from transformers import pipeline
import json
import pandas as pd
import os
from openai import OpenAI
from dotenv import load_dotenv
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
import streamlit as st
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
csv_path = os.path.join(BASE_DIR, "data", "sample.csv")

    
# OPENAI API
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    
# Hugging Face pipeline ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ê°ì •ë¶„ì„ìš©)
pipe = pipeline("text-classification", model="hun3359/klue-bert-base-sentiment")

# ê°ì • ì ìˆ˜ ì •ì˜
emotion_scores = {
    "ë¶„ë…¸": 0,          # ê°€ì¥ ë¶€ì •ì 
    "íˆ´íˆ´ëŒ€ëŠ”": 5,
    "ì¢Œì ˆí•œ": 8,
    "ì§œì¦ë‚´ëŠ”": 4,
    "ë°©ì–´ì ì¸": 10,
    "ì•…ì˜ì ì¸": 3,
    "ì•ˆë‹¬í•˜ëŠ”": 12,
    "êµ¬ì—­ì§ˆ ë‚˜ëŠ”": 1,
    "ë…¸ì—¬ì›Œí•˜ëŠ”": 2,
    "ì„±ê°€ì‹ ": 15,
    "ìŠ¬í””": 20,
    "ì‹¤ë§í•œ": 22,
    "ë¹„í†µí•œ": 18,
    "í›„íšŒë˜ëŠ”": 19,
    "ìš°ìš¸í•œ": 25,
    "ë§ˆë¹„ëœ": 30,
    "ì—¼ì„¸ì ì¸": 35,
    "ëˆˆë¬¼ì´ ë‚˜ëŠ”": 28,
    "ë‚™ë‹´í•œ": 26,
    "í™˜ë©¸ì„ ëŠë¼ëŠ”": 33,
    "ë¶ˆì•ˆ": 40,
    "ë‘ë ¤ìš´": 42,
    "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”": 38,
    "ì·¨ì•½í•œ": 45,
    "í˜¼ë€ìŠ¤ëŸ¬ìš´": 48,
    "ë‹¹í˜¹ìŠ¤ëŸ¬ìš´": 44,
    "íšŒì˜ì ì¸": 46,
    "ê±±ì •ìŠ¤ëŸ¬ìš´": 41,
    "ì¡°ì‹¬ìŠ¤ëŸ¬ìš´": 47,
    "ì´ˆì¡°í•œ": 43,
    "ìƒì²˜": 37,
    "ì§ˆíˆ¬í•˜ëŠ”": 39,
    "ë°°ì‹ ë‹¹í•œ": 36,
    "ê³ ë¦½ëœ": 34,
    "ì¶©ê²© ë°›ì€": 32,
    "ê°€ë‚œí•œ ë¶ˆìš°í•œ": 31,
    "í¬ìƒëœ": 29,
    "ì–µìš¸í•œ": 27,
    "ê´´ë¡œì›Œí•˜ëŠ”": 23,
    "ë²„ë ¤ì§„": 24,
    "ë‹¹í™©": 21,
    "ê³ ë¦½ëœ(ë‹¹í™©í•œ)": 16,
    "ë‚¨ì˜ ì‹œì„ ì„ ì˜ì‹í•˜ëŠ”": 17,
    "ì™¸ë¡œìš´": 13,
    "ì—´ë“±ê°": 11,
    "ì£„ì±…ê°ì˜": 14,
    "ë¶€ë„ëŸ¬ìš´": 6,
    "í˜ì˜¤ìŠ¤ëŸ¬ìš´": 7,
    "í•œì‹¬í•œ": 9,
    "í˜¼ë€ìŠ¤ëŸ¬ìš´(ë‹¹í™©í•œ)": 49,   # ìµœì†Œ ë¶€ì •

    "ê¸°ì¨": 60,          # ê¸ì • ì‹œì‘
    "ê°ì‚¬í•˜ëŠ”": 70,
    "ì‹ ë¢°í•˜ëŠ”": 65,
    "í¸ì•ˆí•œ": 68,
    "ë§Œì¡±ìŠ¤ëŸ¬ìš´": 75,
    "í¥ë¶„": 80,
    "ëŠê¸‹": 72,
    "ì•ˆë„": 77,
    "ì‹ ì´ ë‚œ": 90,
    "ìì‹ í•˜ëŠ”": 100      # ê°€ì¥ ê¸ì •ì 
}

# CSV ë¡œë“œ + ë‚ ì§œ ë³€í™˜ + ì •ë ¬ í•¨ìˆ˜
def load_and_prepare_data():
    if os.path.exists(csv_path) and os.stat(csv_path).st_size > 0:
        df = pd.read_csv(csv_path, encoding="utf-8")
        df["date"] = pd.to_datetime(df["date"])  # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        df["score"] = pd.to_numeric(df["score"], errors='coerce')  # ìˆ«ì ë³€í™˜
        df = df.sort_values(by="date")
        return df
    return pd.DataFrame()

# ì¼ê¸° ë¶„ì„ í•¨ìˆ˜
def analyze_diary(text):
    ## ê°ì •ë¶„ì„
    result = pipe(text)[0]
    label = result['label'].strip()
    score = emotion_scores.get(label, 50)

    ## ìš”ì•½ ìƒì„± (GPT API í˜¸ì¶œ)
    summary_prompt = f"ë‹¤ìŒ ì¼ê¸°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜: \n{text}"

    ## GPT í˜¸ì¶œ
    summary = client.chat.completions.create(
        model= "gpt-4o-mini",
        messages=[{"role":"user","content":summary_prompt}]
    ).choices[0].message.content.strip()


    ## ê³µê° ìƒì„± (GPT API í˜¸ì¶œ)
    empathy_prompt = f"ì‚¬ìš©ìì˜ í•˜ë£¨: {text}\në„ˆëŠ” ë”°ëœ»í•˜ê²Œ ê³µê°í•´ì£¼ëŠ” AI ì¹œêµ¬ì•¼. í•œ ë¬¸ì¥ìœ¼ë¡œ ê³µê°í•´ì¤˜."

    ## GPT í˜¸ì¶œ
    empathy = client.chat.completions.create(
        model="gpt-4o-mini",
        messages = [{"role":"user","content":empathy_prompt}]
    ).choices[0].message.content.strip()

    ## csvì— ì €ì¥
    new_entry = {
        "date": pd.Timestamp.now().strftime("%Y-%m-%d"),
        "text": text,
        "label": label,
        "score": score,
        "summary": summary,
        "empathy": empathy
    }
 
    try:
        if os.path.exists(csv_path) and os.stat(csv_path).st_size > 0:
            df_existing = pd.read_csv(csv_path, encoding="utf-8")
        else:
            df_existing = pd.DataFrame()
    except pd.errors.EmptyDataError:
        df_existing = pd.DataFrame()

    # ìƒˆ ë°ì´í„° ì¶”ê°€
    df_existing = pd.concat([df_existing, pd.DataFrame([new_entry])], ignore_index=True)

    # CSV ì €ì¥
    df_existing.to_csv(csv_path, index=False, encoding="utf-8-sig")
    
    plot_emotion_distribution()
    plot_emotion_trend()
    
    return f"ê°ì •: {label}\nì ìˆ˜: {score}\nìš”ì•½: {summary}\nê³µê°: {empathy}"


# ê°ì • ë¶„í¬ ê·¸ë˜í”„
def plot_emotion_distribution():
    df = load_and_prepare_data()
    if df.empty:
        return None
    
    font_path = r"C:\Users\user\Downloads\malgun-gothic\malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    rc('font', family=font_name)

    fig, ax = plt.subplots(figsize=(10, 5))
    df["label"].value_counts().plot(kind="bar", ax=ax)
    ax.set_title("ê°ì • ë¶„í¬")
    ax.set_xlabel("ê°ì •")
    ax.set_ylabel("ë¹ˆë„")
    plt.tight_layout()
    
    return fig  # Figure ê°ì²´ ë°˜í™˜

def plot_emotion_trend():
    df = load_and_prepare_data()
    if df.empty:
        return None
    
    font_path = r"C:\Users\user\Downloads\malgun-gothic\malgun.ttf"
    font_name = font_manager.FontProperties(fname=font_path).get_name()
    rc('font', family=font_name)

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(df["date"], df["score"], marker='o')
    ax.set_title("ê°ì • ì ìˆ˜ ë³€í™”")
    ax.set_xlabel("ë‚ ì§œ")
    ax.set_ylabel("ê°ì • ì ìˆ˜(0=ë¶€ì •, 100=ê¸ì •)")
    plt.xticks(rotation=45)
    ax.grid(True)
    plt.tight_layout()
    
    return fig  # Figure ê°ì²´ ë°˜í™˜


# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

## ì„ë² ë”© ìƒì„± í•¨ìˆ˜
def get_embedding(text):
    return embedder.encode(text, convert_to_numpy=True)

## FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
def build_faiss_index(texts):
    embeddings = [get_embedding(t) for t in texts]
    dim = embeddings[0].shape[0]
    index = faiss.IndexFlatL2(dim)
    index.add(np.array(embeddings))
    return index

def find_similar(text, index, texts, top_k = 3):
    query_vec = get_embedding(text).reshape(1, -1)
    distances, indices = index.search(query_vec, top_k)
    return [texts[i] for i in indices[0]]

def search_similar_diary(text):
    df = load_and_prepare_data()
    if df.empty:
        return "ì¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤."
    texts = df["text"].tolist()
    index = build_faiss_index(texts)
    similar_texts = find_similar(text, index, texts)
    return "\n\n".join(similar_texts)

st.title("ğŸ““ ê°ì •ì¼ê¸° ë¶„ì„ ë° ì‹œê°í™”")

# ì…ë ¥
diary_input = st.text_area("ì˜¤ëŠ˜ì˜ ì¼ê¸°ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")

# ë¶„ì„
if st.button("ì¼ê¸° ë¶„ì„ ë° ì €ì¥"):
    if diary_input.strip():
        result = analyze_diary(diary_input)
        st.success(result)
    else:
        st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ê°ì • ë¶„í¬
if st.button("ê°ì • ë¶„í¬ ê·¸ë˜í”„ ë³´ê¸°"):
    fig = plot_emotion_distribution()
    if fig is not None:
        st.pyplot(fig)
    else:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ê°ì • ì¶”ì´
if st.button("ê°ì • ì ìˆ˜ ì¶”ì´ ê·¸ë˜í”„ ë³´ê¸°"):
    fig = plot_emotion_trend()
    if fig is not None:
        st.pyplot(fig)
    else:
        st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ìœ ì‚¬ ì¼ê¸° ê²€ìƒ‰
if st.button("ìœ ì‚¬í•œ ê³¼ê±° ì¼ê¸° ì°¾ê¸°"):
    if diary_input.strip():
        similar = search_similar_diary(diary_input)
        st.info(similar)
    else:
        st.warning("ì¼ê¸°ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")